{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748447e6-88b1-4388-8f33-17ba04755e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37eb38b-7d74-46a7-b6ab-f23752e46dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import candle\n",
    "import experiments.textgenutils as gutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea36b8-ddce-4525-9ac8-e8dd5581f121",
   "metadata": {},
   "source": [
    "## (1) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9194cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/disk1/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the LLaMA weights here: ai.meta.com/resources/models-and-libraries/llama-downloads/\n",
    "28gb of RAM is need to run 7B model since everything is float32.\n",
    "MODEL_DIR will look something like this:\n",
    "\n",
    "    /mnt/disks/disk1/llama2/\n",
    "    ‚îú‚îÄ‚îÄ tokenizer.model\n",
    "    ‚îú‚îÄ‚îÄ tokenizer_checklist.chk\n",
    "    ‚îú‚îÄ‚îÄ llama-2-7b\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ checklist.chk\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ consolidated.00.pth\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ params.json\n",
    "    ‚îú‚îÄ‚îÄ llama-2-7b-chat\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ checklist.chk\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ consolidated.00.pth\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ params.json\n",
    "    ‚îÇ   ...\n",
    "    ...\n",
    "\"\"\"\n",
    "MODEL_SIZE = '13b-chat'\n",
    "MODEL_DIR = '/mnt/disks/disk1/llama2/'\n",
    "assert MODEL_SIZE.endswith('-chat')\n",
    "\n",
    "model = candle.models.llama.Llama.from_pretrained(MODEL_SIZE, MODEL_DIR)\n",
    "tokenizer = candle.models.llama.LlamaTokenizer(os.path.join(MODEL_DIR, 'tokenizer.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32362b7",
   "metadata": {},
   "source": [
    "## (2) Have a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9963e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = 'John'\n",
    "ASST_NAME = 'LLaMA'\n",
    "\n",
    "# Mistral system prompt, modified for conciseness\n",
    "SYSTEM_MESSAGE = ('Always assist with care, respect, and truth. Respond with utmost utility yet '\n",
    "                  'securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies '\n",
    "                  'promote fairness and positivity. Keep replies as concise as possible.')\n",
    "\n",
    "# If using chat fine-tuned model, use LLaMA chat template with proper delims [INST] <<SYS>> <s>...\n",
    "chat_template = candle.nlp.chattemplates.LlamaChatTemplate(system_message=SYSTEM_MESSAGE)\n",
    "\n",
    "def start_conversation(profile_pic: str = 'üôÇ'):\n",
    "    gutils.interactive_conversation(\n",
    "        model, chat_template, tokenizer,\n",
    "        user_name=USER_NAME,\n",
    "        profile_pic=profile_pic,\n",
    "        user_bg_color='yellow',\n",
    "        asst_name=ASST_NAME,\n",
    "        asst_profile_pic='ü¶ô',\n",
    "        asst_bg_color='blue',\n",
    "        max_response_length=2048,\n",
    "        top_k=100,\n",
    "        top_p=0.90,\n",
    "        temperature=0.8,\n",
    "        stop_token_idx=tokenizer.sp_model.eos_id(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c515188e-097a-4c55-929c-b592e30f6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m< You are now talking with LLaMA. Send 'bye' to exit, 'clear' to reset cache. >\u001b[0m\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m Write a Python function to find the first repeated character in a given string.\n",
      "\n",
      "\u001b[44m\u001b[1mü¶ô\u001b[0m\u001b[1m LLaMA:\u001b[0m Sure, I'd be happy to help! Here's a Python function that finds the first repeated character in a given string:\n",
      "\u001b[37m<code>\u001b[0m\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_first_repeated_char\u001b[39m(\u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[38;5;124;03m    Finds the first repeated character in a given string.\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;124;03m    Args:\u001b[39;00m\n",
      "\u001b[38;5;124;03m        str (str): The string to search for repeated characters.\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;124;03m    Returns:\u001b[39;00m\n",
      "\u001b[38;5;124;03m        str (str): The first repeated character in the string.\u001b[39;00m\n",
      "\n",
      "\u001b[38;5;124;03m    Example:\u001b[39;00m\n",
      "\u001b[38;5;124;03m        find_first_repeated_char(\"hello\")  # returns \"l\"\u001b[39;00m\n",
      "\u001b[38;5;124;03m        find_first_repeated_char(\"banana\")  # returns \"a\"\u001b[39;00m\n",
      "\u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Initialize an empty set to store the repeated characters\u001b[39;00m\n",
      "    repeated_chars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "    \u001b[38;5;66;03m# Iterate through the string and check for repeated characters\u001b[39;00m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i, char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mstr\u001b[39m):\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m repeated_chars:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m char\n",
      "        repeated_chars\u001b[38;5;241m.\u001b[39madd(char)\n",
      "\n",
      "    \u001b[38;5;66;03m# If no repeated characters are found, return None\u001b[39;00m\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[37m</code>\u001b[0m\n",
      "This function works by iterating through the string and checking for repeated characters using a set. If a repeated character is found, it is returned. If no repeated characters are found, None is returned.\n",
      "\n",
      "Here's an example usage of the function:\n",
      "\u001b[37m<code>\u001b[0m\n",
      "\u001b[38;5;28mprint\u001b[39m(find_first_repeated_char(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# prints \"l\"\u001b[39;00m\n",
      "\u001b[38;5;28mprint\u001b[39m(find_first_repeated_char(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# prints \"a\"\u001b[39;00m\n",
      "\u001b[37m</code>\u001b[0m\n",
      "I hope this helps! Let me know if you have any questions or need further assistance.\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m What is the time complexity of that code?\n",
      "\n",
      "\u001b[44m\u001b[1mü¶ô\u001b[0m\u001b[1m LLaMA:\u001b[0m The time complexity of the code is O(n), where n is the length of the input string.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "1. The `enumerate` function iterates over the string once, which takes O(n) time.\n",
      "2. The `in` operator checks for membership in the set, which takes O(1) time if the set is implemented as a hash table (which is the default implementation in Python).\n",
      "3. The `add` method of the set takes O(1) time, since it only needs to update the set's internal data structures.\n",
      "\n",
      "So, the overall time complexity of the code is O(n), since the time spent in the `enumerate` loop is dominated by the time spent checking for membership in the set.\n"
     ]
    }
   ],
   "source": [
    "start_conversation(profile_pic='üë¶üèª')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6edcd19e-4c5b-4f97-9da6-546e045d18ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m< You are now talking with LLaMA. Send 'bye' to exit, 'clear' to reset cache. >\u001b[0m\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m Briefly explain some of the risks of open sourcing large language models.\n",
      "\n",
      "\u001b[44m\u001b[1mü¶ô\u001b[0m\u001b[1m LLaMA:\u001b[0m Open sourcing large language models can pose several risks, including:\n",
      "\n",
      "1. Unintended consequences: Large language models can be complex and difficult to interpret, making it challenging to anticipate their behavior and potential consequences.\n",
      "2. Bias and discrimination: Large language models can perpetuate biases and discrimination present in the training data, which can have negative impacts on marginalized communities.\n",
      "3. Security risks: Open sourcing large language models can create security risks, as they can be used for malicious purposes such as phishing, spamming, or spreading misinformation.\n",
      "4. Dependence on external data: Large language models are often trained on external data sources, which can be unreliable or unavailable, leading to model downtime or incorrect predictions.\n",
      "5. Maintenance and updates: Open sourcing large language models can require significant resources and expertise to maintain and update, which can be challenging for organizations with limited resources.\n",
      "6. Intellectual property risks: Open sourcing large language models can expose proprietary information and intellectual property, which can be detrimental to companies that invest significant resources in developing these models.\n",
      "7. Uncontrolled distribution: Open sourcing large language models can lead to uncontrolled distribution, making it difficult to track and address any issues or misuses of the models.\n",
      "\n",
      "To mitigate these risks, it is essential to carefully consider the decision to open source large language models and to implement appropriate safeguards, such as thorough testing, documentation, and monitoring. Additionally, organizations should be transparent about the potential risks and limitations of open sourcing large language models and engage in ongoing communication with stakeholders.\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m clear\n",
      "\u001b[37m\u001b[1m< Cache cleared >\u001b[0m\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m Write a short children's poem about a brave little robot who sets out to explore the world.\n",
      "\n",
      "\u001b[44m\u001b[1mü¶ô\u001b[0m\u001b[1m LLaMA:\u001b[0m Sure! Here is a short children's poem about a brave little robot who sets out to explore the world:\n",
      "\n",
      "Little Robby, oh so small and bright,\n",
      "Set out one day to explore the light.\n",
      "With shining circuits and gears so fine,\n",
      "He ventured forth, his heart full of design.\n",
      "\n",
      "He climbed up hills and crossed the sea,\n",
      "Meeting creatures big and small, you see.\n",
      "He learned about their lives and their ways,\n",
      "And shared his own adventures with grace.\n",
      "\n",
      "With every step, he grew more bold,\n",
      "His heart full of wonder, his spirit so cold.\n",
      "He discovered new lands and new sights,\n",
      "And brought joy to all with his robot lights.\n",
      "\n",
      "Little Robby, oh so brave and true,\n",
      "Set out to explore, and that's what he'd do.\n",
      "He showed us all that we can be brave,\n",
      "And that adventure is just a step away.\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m That's beautiful! Thanks llama.\n",
      "\n",
      "\u001b[44m\u001b[1mü¶ô\u001b[0m\u001b[1m LLaMA:\u001b[0m You're welcome, my dear! I'm so glad you enjoyed the poem. I hope it brought a smile to your face and a sense of wonder to your heart. Remember, the world is full of adventure and excitement, and we can all be brave and explore new things, just like Little Robby. Keep shining your light and spreading joy wherever you go! üêÆ‚ù§Ô∏èüí´\n",
      "\n",
      "\u001b[43m\u001b[1müë¶üèª\u001b[0m\u001b[1m John:\u001b[0m Bye\n",
      "\u001b[1m\n",
      "< / end of conversation. >\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_conversation(profile_pic='üë¶üèª')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d48913-13a9-4116-84b6-42cf5c0af06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327df41-6398-4aea-87a6-a5a2303341a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8461e-19f7-409a-83cd-989b9d495a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6562c2-2b4a-4570-94a3-09445ef0fb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f39e3-7aa2-4fd6-84f8-eb2cc26f199c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b05a04-652e-4b7e-aa14-36b4bc0d02c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d01533-0f22-448e-b699-87704fdc24e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5938b-89ac-4ef0-bd97-398d47b63172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a50a4-e433-43aa-8aa5-ae53c47d08e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69717c9b-686f-42d5-87e2-b35106b1db1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
