{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7ff890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70c3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Union\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import candle\n",
    "import experiments.textgenutils as gutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170016c9",
   "metadata": {},
   "source": [
    "## (1) Initialize Model with Pre-trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbbef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl']\n",
    "#    gpt2:         124M params\n",
    "#    gpt2-medium:  354M params\n",
    "#    gpt2-large:   774M params\n",
    "#    gpt2-xl:    1,557M params\n",
    "\n",
    "model = candle.models.gpt.GPT.from_pretrained('gpt2-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182e26b",
   "metadata": {},
   "source": [
    "## (2) Profile Speedup and Memory Consumption from KV Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a876c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_kv_cache_generation_time_and_memory_consumption(prompt: str,\n",
    "                                                            n_tokens_to_generate: int):\n",
    "    tokenizer = candle.models.gpt.GPT2BPETokenizer()\n",
    "    indices = tokenizer.encode(prompt)\n",
    "\n",
    "    print('Prompt:', prompt)\n",
    "    print('Tokens to generate:', n_tokens_to_generate)\n",
    "    \n",
    "    model_param_fp32s = int(sum([np.prod(p.shape) for p in model.parameters().values()]))\n",
    "    print('Model Param Memory Consumption:', f'{model_param_fp32s / 1e6 * 4:.1f} MB')\n",
    "    print()\n",
    "\n",
    "    for use_kv_cache in [False, True]:\n",
    "        if use_kv_cache:\n",
    "            print('USING KV CACHE')\n",
    "            print('==============')\n",
    "        else:\n",
    "            print('NOT USING KV CACHE')\n",
    "            print('==================')\n",
    "\n",
    "        model.clear_kv_cache()\n",
    "\n",
    "        generator = gutils.generate_text(model, tokenizer, prompt,\n",
    "                                         n_tokens_to_generate=n_tokens_to_generate,\n",
    "                                         beam_size=1,\n",
    "                                         top_k=100,\n",
    "                                         top_p=0.95,\n",
    "                                         sample=False,\n",
    "                                         use_kv_cache=use_kv_cache)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = ''.join(list(generator))\n",
    "        end_time = time.time()\n",
    "\n",
    "        if use_kv_cache:\n",
    "            kv_cache_fp32s = np.prod(model.decoder_blocks[0].attn.kv_cache[0].shape)\n",
    "            peak_kv_cache_fp32s = (len(indices) + n_tokens_to_generate) * kv_cache_fp32s // len(indices)\n",
    "        else:\n",
    "            peak_kv_cache_fp32s = 0\n",
    "\n",
    "        print('Generation time:'.ljust(28), f'{end_time - start_time:.1f} sec')\n",
    "        print('KV Cache Memory Consumption:'.ljust(28), f'{peak_kv_cache_fp32s / 1e6 * 4:.1f} MB')\n",
    "        print()\n",
    "\n",
    "    print('Response:', response.lstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78b482",
   "metadata": {},
   "source": [
    ">     Note: KV cache memory figures are only on single batch and a relatively small context length,\n",
    "    and in practice will be much larger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6588905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Note: KV cache memory figures are only on single batch and a relatively small context length, and in practice will be much larger.\n",
      "Tokens to generate: 100\n",
      "Model Param Memory Consumption: 3096.1 MB\n",
      "\n",
      "NOT USING KV CACHE\n",
      "==================\n",
      "Generation time:             168.0 sec\n",
      "KV Cache Memory Consumption: 0.0 MB\n",
      "\n",
      "USING KV CACHE\n",
      "==============\n",
      "Generation time:             28.5 sec\n",
      "KV Cache Memory Consumption: 0.7 MB\n",
      "\n",
      "Response: The KV cache is a memory-mapped file that is used to store the data that is to be processed by the kernel. The KV cache is a special type of memory that is used to store data that is to be processed by the kernel. The KV cache is a special type of memory that is used to store data that is to be processed by the kernel. The KV cache is a special type of memory that is used to store data that is to be processed\n"
     ]
    }
   ],
   "source": [
    "profile_kv_cache_generation_time_and_memory_consumption(\n",
    "    'Note: KV cache memory figures are only on single batch and a relatively small context length, '\n",
    "    'and in practice will be much larger.',\n",
    "    n_tokens_to_generate = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4f0b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The young hacker stumbles upon a secret that could change the fate of both worlds.\n",
      "Tokens to generate: 100\n",
      "Model Param Memory Consumption: 3096.1 MB\n",
      "\n",
      "NOT USING KV CACHE\n",
      "==================\n",
      "Generation time:             142.4 sec\n",
      "KV Cache Memory Consumption: 0.0 MB\n",
      "\n",
      "USING KV CACHE\n",
      "==============\n",
      "Generation time:             28.1 sec\n",
      "KV Cache Memory Consumption: 0.6 MB\n",
      "\n",
      "Response: The Dark Crystal: Age of Resistance\n",
      "\n",
      "In this prequel to the fantasy classic, three young Gelflings inspire a rebellion against the cruel emperor when they discover a horrifying secret.\n",
      "\n",
      "The Curious Creations of Christine McConnell\n",
      "\n",
      "Wickedly talented baker and artist Christine McConnell fills her home with haunting confections, creepy crafts -- and wildly inappropriate creatures.\n",
      "\n",
      "The Kindergarten Teacher\n",
      "\n",
      "A devoted teacher takes interest in a young student's creative potential after hearing his\n"
     ]
    }
   ],
   "source": [
    "profile_kv_cache_generation_time_and_memory_consumption(\n",
    "    'The young hacker stumbles upon a secret that could change the fate of both worlds.',\n",
    "    n_tokens_to_generate = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e895ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: A lone astronaut floats weightlessly in the vast expanse of space, their small capsule dwarfed by the swirling nebulae and distant galaxies. The astronaut's gaze drifts towards the Earth, a tiny blue marble suspended in the cosmic void, their home planet now a distant memory.\n",
      "Tokens to generate: 50\n",
      "Model Param Memory Consumption: 3096.1 MB\n",
      "\n",
      "NOT USING KV CACHE\n",
      "==================\n",
      "Generation time:             87.4 sec\n",
      "KV Cache Memory Consumption: 0.0 MB\n",
      "\n",
      "USING KV CACHE\n",
      "==============\n",
      "Generation time:             15.3 sec\n",
      "KV Cache Memory Consumption: 0.5 MB\n",
      "\n",
      "Response: The astronaut's eyes are closed, their body weightless, their mind free to wander. They are alone in the vastness of space.\n",
      "\n",
      "The astronaut's eyes are closed, their body weightless, their mind free to wander.\n"
     ]
    }
   ],
   "source": [
    "profile_kv_cache_generation_time_and_memory_consumption(\n",
    "    'A lone astronaut floats weightlessly in the vast expanse of space, their small capsule '\n",
    "    'dwarfed by the swirling nebulae and distant galaxies. The astronaut\\'s gaze drifts towards '\n",
    "    'the Earth, a tiny blue marble suspended in the cosmic void, their home planet now a distant memory.',\n",
    "    n_tokens_to_generate = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b043b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is an Apple iPhone?\n",
      "Tokens to generate: 50\n",
      "Model Param Memory Consumption: 3096.1 MB\n",
      "\n",
      "NOT USING KV CACHE\n",
      "==================\n",
      "Generation time:             32.0 sec\n",
      "KV Cache Memory Consumption: 0.0 MB\n",
      "\n",
      "USING KV CACHE\n",
      "==============\n",
      "Generation time:             13.6 sec\n",
      "KV Cache Memory Consumption: 0.3 MB\n",
      "\n",
      "Response: The iPhone is a mobile phone that is used to make calls, send and receive text messages, and access the Internet. It is also used to make and receive phone calls, send and receive text messages, and access the Internet.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_kv_cache_generation_time_and_memory_consumption(\n",
    "    'What is an Apple iPhone?',\n",
    "    n_tokens_to_generate = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca002c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1bc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9df3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
